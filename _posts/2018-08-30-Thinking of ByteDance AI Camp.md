---
layout:     post                    # 使用的布局（不需要改）
title:      字节跳动AI夏令营参营感悟               # 标题 
subtitle:   感悟 #副标题
date:       2018-08-30              # 时间
author:     Ke Sun                      # 作者
header-img: img/post-bg-2015.jpg    #这篇文章标题背景图片
catalog: true                       # 是否归档
tags:                               #标签
    - 感悟
---    

# 字节跳动AI夏令营感悟  
>机缘巧合参加了2018年字节跳动第一届AI夏令营，收获很大，对每个演讲做一份自己的感悟记录。
## 营仪式演讲：华巍  
* 公司目标：全球创作与交流平台  
(1)科技公司越来越成为这个时代的趋势。国外：Google，Amazon，Facebook + Apple，Microsoft；国内：腾讯、阿里、百度；滴滴、美团、头条；京东、小米  
(2)关注一个公司看两个指标：a DAU：每日活跃度 b 营业收入  
(3)公司的发展存在着更替，很多公司成为了伟大的公司，新时代也孕育这很多新兴的公司，未来去成为伟大的公司  
* 做事目标：和优秀的人做有挑战的事，并长期在一起  
* 未来：  
(1)一个人从物质最终会向精神去过度，要有长远的目标  
(2)亚历山大大帝征服世界的同时不忘向自己的老师去请教问题，人在追求物质的同时也要去追求自己的精神  
## 马维英  
* 字节跳动的定位是信息服务：人和信息的链接  
* 第四次工业革命：人工智能  
* 多模态的公司才能成为伟大的公司，能够在不同的商业模式中成功转换成功变型不断创新才是伟大的公司  
* 好的科技公司拥抱各种技术，各种AI的技术都能够有很大的用武之地  
(1)机器学习  
(2)计算机视觉  
(3)自然语言处理  
(4)大数据与数据挖掘  
(5)分布式系统  
(6)计算机图形学  
(7)图与网络  
* 互联网三大核心技术：推荐、广告、搜索  
* 利用AI技术做出产品实现人类的智能生活和工作  
## 概率机器学习：朱军  
* 概率机器学习是机器学习的一个分支，用概率统计方法去研究机器学习问题， 分为下面五个研究问题  
(1)statistical machine learning   
(2)scalable optimization algorithms  
(3)概率编程  
(4)robustness/interpretable(hot)  
(5)casual/relation inference(Judea Pearl, hot)  
* 生成模型(e.g. GMM) vs 判别模型(e.g. Logistic regression), 生成分类器(P(x,y) naive bayes) vs 判别分类器(P(y|x),logistic)   
* Naive Bayes —— Deep Generative Model, 模型虽然花哨，但本质上问题不变，原理是一样的    
>博士需要很好的基础，对基础问题要理解很扎实  
## 产品系统与算法系统：项亮  
* 好的算法工程师核心是解决问题，思路：发现问题、判断问题、拆解和转化问题、 解决问题
* 思维：优雅的解决问题，开发高效的工具，程序员要学会懒惰，解放自己才会成长——不会偷懒的工程师不是好的工程师   
## An Exploration to non-NN style Deep Learning: 周志华  
* 领域分为三个方向：机器学习（一定要搞清楚原理是什么），计算机视觉、自然语言处理（方法应用）  
* 深度学习：深度神经网络+其他深度模型non-nn style 
* 思考深度神经网络相比于其他模型之所以成功的核心因素 
模型复杂度高+数据量大缓解overfitting——shallow model万有逼近定理仍然效果比不上深度学习——深度神经网络这种特殊的结构使得representation能力大大提高才是根本原因  、
(1)逐层处理的结构(svm not)    
(2)feature extraction power(decision tree not)   
(3)有效的模型复杂度+big data缓解overfitting  
* end-to-end：将表征学习和分类一起优化，这一点并不本质，更重要的是表征这一部分   
* 为什么考虑深度学习的其他深度模型，深度神经网络有以下问题  
(1)大量调参  
(2)可重复性差  
(3)无法自适应去选择模型的复杂度  
NN本质是可微、非线性模块，未来应该拓展到不可微的情况。  
* 不同的问题是采用的不同的方法：  
(1)传统离散数据：ensemble best(KDD cup都是集成学习解决的) ，离散数据用CNN其实很不自然    
(2)AI task（复杂信号处理任务）：深度学习模型  。这种过度从问题的复杂度来说也是非常的自然。  
* 提出了gcForest，原理是模型深度神经网络设计了深度森林（保留了逐层处理的能力），并进行有效的特征变换，深度又保证了模型复杂度，最后证明了在image classification上具有很好的效果。  
* gcForest这种深度不可微的构建，保留了深度神经网络的能力，同时可以处理不可微单元，是深度神经网络的有力补充。
## 深度学习入门：李磊  
* 如何判断你对问题真正理解了，能够自己动手推公式，并且把这个方法给另外一个人说清楚。  
>几个基础知识：(1)BP推导(2)Margin loss(3)ERM vs 其他loss  
* tanh[-1,1]表示信号，sigmoid[0,1]表示强弱  
* NLP模型演变：RNN,GRU,LSTM,Attention   
##   





















