---
layout:     post                    # 使用的布局（不需要改）
title:      字节跳动AI夏令营参营感悟               # 标题 
subtitle:   感悟 #副标题
date:       2018-08-30              # 时间
author:     Ke Sun                      # 作者
header-img: img/post-bg-2015.jpg    #这篇文章标题背景图片
catalog: true                       # 是否归档
tags:                               #标签
    - 感悟
---    

# 字节跳动AI夏令营感悟  
>机缘巧合参加了2018年字节跳动第一届AI夏令营，收获很大，对每个演讲做一份自己的感悟记录。
## 营仪式演讲：华巍  
* 公司目标：全球创作与交流平台  
(1)科技公司越来越成为这个时代的趋势。国外：Google，Amazon，Facebook + Apple，Microsoft；国内：腾讯、阿里、百度；滴滴、美团、头条；京东、小米  
(2)关注一个公司看两个指标：a DAU：每日活跃度 b 营业收入  
(3)公司的发展存在着更替，很多公司成为了伟大的公司，新时代也孕育这很多新兴的公司，未来去成为伟大的公司  
* 做事目标：和优秀的人做有挑战的事，并长期在一起  
* 未来：  
(1)一个人从物质最终会向精神去过度，要有长远的目标  
(2)亚历山大大帝征服世界的同时不忘向自己的老师去请教问题，人在追求物质的同时也要去追求自己的精神  
## 马维英  
* 字节跳动的定位是信息服务：人和信息的链接  
* 第四次工业革命：人工智能  
* 多模态的公司才能成为伟大的公司，能够在不同的商业模式中成功转换成功变型不断创新才是伟大的公司  
* 好的科技公司拥抱各种技术，各种AI的技术都能够有很大的用武之地  
(1)机器学习  
(2)计算机视觉  
(3)自然语言处理  
(4)大数据与数据挖掘  
(5)分布式系统  
(6)计算机图形学  
(7)图与网络  
* 互联网三大核心技术：推荐、广告、搜索  
* 利用AI技术做出产品实现人类的智能生活和工作  
## 概率机器学习：朱军  
* 概率机器学习是机器学习的一个分支，用概率统计方法去研究机器学习问题， 分为下面五个研究问题  
(1)statistical machine learning   
(2)scalable optimization algorithms  
(3)概率编程  
(4)robustness/interpretable(hot)  
(5)casual/relation inference(Judea Pearl, hot)  
* 生成模型(e.g. GMM) vs 判别模型(e.g. Logistic regression), 生成分类器(P(x,y) naive bayes) vs 判别分类器(P(y|x),logistic)   
* Naive Bayes —— Deep Generative Model, 模型虽然花哨，但本质上问题不变，原理是一样的    
>博士需要很好的基础，对基础问题要理解很扎实  
## 产品系统与算法系统：项亮  
* 好的算法工程师核心是解决问题，思路：发现问题、判断问题、拆解和转化问题、 解决问题
* 思维：优雅的解决问题，开发高效的工具，程序员要学会懒惰，解放自己才会成长——不会偷懒的工程师不是好的工程师   
## An Exploration to non-NN style Deep Learning: 周志华  
* 领域分为三个方向：机器学习（一定要搞清楚原理是什么），计算机视觉、自然语言处理（方法应用）  
* 深度学习：深度神经网络+其他深度模型non-nn style 
* 思考深度神经网络相比于其他模型之所以成功的核心因素 
模型复杂度高+数据量大缓解overfitting——shallow model万有逼近定理仍然效果比不上深度学习——深度神经网络这种特殊的结构使得representation能力大大提高才是根本原因  、
(1)逐层处理的结构(svm not)    
(2)feature extraction power(decision tree not)   
(3)有效的模型复杂度+big data缓解overfitting  
* end-to-end：将表征学习和分类一起优化，这一点并不本质，更重要的是表征这一部分   
* 为什么考虑深度学习的其他深度模型，深度神经网络有以下问题  
(1)大量调参  
(2)可重复性差  
(3)无法自适应去选择模型的复杂度  
NN本质是可微、非线性模块，未来应该拓展到不可微的情况。  
* 不同的问题是采用的不同的方法：  
(1)传统离散数据：ensemble best(KDD cup都是集成学习解决的) ，离散数据用CNN其实很不自然    
(2)AI task（复杂信号处理任务）：深度学习模型  。这种过度从问题的复杂度来说也是非常的自然。  
* 提出了gcForest，原理是模型深度神经网络设计了深度森林（保留了逐层处理的能力），并进行有效的特征变换，深度又保证了模型复杂度，最后证明了在image classification上具有很好的效果。  
* gcForest这种深度不可微的构建，保留了深度神经网络的能力，同时可以处理不可微单元，是深度神经网络的有力补充。
## 深度学习入门：李磊  
* 如何判断你对问题真正理解了，能够自己动手推公式，并且把这个方法给另外一个人说清楚。  
>几个基础知识：(1)BP推导(2)Margin loss(3)ERM vs 其他loss  
* tanh[-1,1]表示信号，sigmoid[0,1]表示强弱  
* NLP模型演变：RNN,GRU,LSTM,Attention   
## 计算机视觉：王长虎  
计算机视觉的五大分支：  
* 分类   
* 检测 
* 分割  
* tracking  
* Pose estimation  
计算机视觉门槛很低，不需要太多先验知识就可以做。  
## 大数据时代的应对：朱文佳  
* mentor：(1)找工作最重要的适合，不一定名声大的公司更适合自己，学习好不代表找的工作一定好 (2)算法是一半想一半做，提高效率不用加班  
* 广义上我们每个人都是开发者，而优秀的开发人员是全栈研发：  
(1)从CPU指令集到操作系统：只会python不理解GPU深层次会留下后遗症，深度学习这种工程师（从数据到模型再到acc）很容易被淘汰，毕竟越来越模块化  
(2)从Hadoop到统计原理  
(3)从机器学习到产品应用  
* 现在技术太快paper太多，能跟上趋势已经不错了，有太多需要学习了  
* 从技术上AI是乐观的，CEO往往是博士毕业转管理，技术总监硕士就够了，工作中不断打磨不断成长   
## 研究经验分享：李航（一个人在人生中某个时间某个阶段发生了一件事都足以改变一个人的一生）  
* 做研究的三个步骤(1)领域很多知识(2)积累过程中有很多想法(3)动手实现想法最终靠谱的想法就是科研  
* 研究 vs 工程：研究是为了开辟新的理论寻找新的方法，工程则是用已有的理论去解决问题  
* 优秀的科学家和工程师之间其实边界并不明显，优秀的科学家一定也是优秀的工程师，研究和工程相辅相成  
* 法拉第电磁感应现象的启示：好的研究来源于好的想法，然后锲而不舍的贪求你，甚至错误的做法会催发真正的真理。专家就是把该犯的错都犯了。  
* 在研究中失败的思路要果断放弃，继续尝试新的思路。  
* 价值观：做深刻本质、同时有应用价值的科研，基于数学且有效的方法才是科学的方法，是我们应该追求的。  
* 恩人的话：你还犹豫什么呀？我对你很了解，你就适合做研究，甭想别的了——最终确定了李航老师以研究为职业  
>人工智能的发展基本全靠机器学习的支撑，但人工智能仍然停留在初级阶段，这个领域的研究仍然是有价值的，抛开浮躁的表面回到问题的本质，即使有时自己的猜想是错误的，但enjoy就够了——对人工智能的看法  
## 深度学习框架：贾扬清caffe之父  
* 真正好的研究工作者，提到这个领域就能想到他的名字  
* y=f(x),现在的nn只不过是一个复合函数的形式 
* 框架的意义：famework is a language for you to write your AI pragrams. 
* 三大类框架：(1)tensorflow(2)pytorch+caffee(3)mxnet+keras  
* 为什么存在这么多的框架都是在做下面两个的balance：  
(1)Developer efficient——pytorch  
(2)Infrastracture efficient——tensorflow  
* 框架的使用方法论：先看问题和需求，再定框架，研究用pytorch(onnx链接caffee)，工业部署tensorflow或其他  
* 通用的框架虽然无法满足个性化需求，但是可以在上层去继承重写来满足个性化定制  
* 框架是整个工业界体系的中间层，平均1年一个新框架，积极拥抱变化。  
## 生成对抗网络：张伟楠  
* 生成模型越来越重要，连续数据(例如图像)用GAN做的很多了，离散数据生成结合强化学习值得探索  
* 离散数据三个层次都可以做(1)single token(2)sequence(3)graph 
* 这个领域在核心问题上硕士没有发言权,博士才有机会有  
* AI趋势发展二维图：横坐标是深度，从shallow model到deep models, 纵坐标是agent的数量，从single model到ensemble, GAN和multiagent RL是两个新范式，未来应该是深度多agent机器学习市场/系统才是真正AI的方向。  
## Data,Hardware,Systems,Tools,Markets：Alex Smolas  
* 英语每个人都是学习痛苦的，但恰恰也是拉开差距的地方。  
* 方法本身没有错，no free lunch，唯一变化的是问题，针对不同的问题去寻找合适的方法，才是机器学习真正的方法论。   
## 文本生成：万小军  
* 弱人工智能——强人工智能——超人工智能，我们现在在第一个阶段。 
* NLP方法在于CNN+RNN的结合   
* NLP的分支：文本生成、智能交互、人机对话、机器翻译   
## Adversarial Machine learning：陈浩  
* 19世纪物理大厦快速搭建起来，只有几朵乌云很多人不屑一顾，但最后正是这几朵乌云颠覆了整个物理大厦，相对论提出颠覆了经典牛顿力学体系   
* 追问深度学习三朵乌云：(1)robustness(2)generalization(3)interpretability  
* 问：Is lacking of robustnees the nature of deep neural networks? 答：maybe, but we are not expected that.如果能用数学的语言系统去阐释这一结论，那么这样的工作是非常深刻的、本质的，DNN的根基自然也会从根本上被动摇。顿时明白了我现在所作的问题的巨大意义。  
* 研究既要考虑意义，也要考价值性。所以一方面做重要的robustness，另一方面做graph model，后者能在实际业务中用得上。  
## 产品运营经验分享：姚帅  
* 科学家和工程师同样需要产品思维，这样才更能做出有价值的工作。   
* 产品和运营的关系：产品去顶层设计，运营具体去执行。   
* 从使用频率和重要性两个角度建立产品的二维思维方式。做出更符合市场的产品。  
* 产品以用户需求为导向，优化用户体验，需要数据分析的思维（宜家的数据分析思路）。  
* 建立产品思维：日常生活中形成产品意识，思考和体验产品的使用。产品和技术相辅相成。  
## 人工智能的挑战：马毅  
* 现在真正的AI都是系统层面上的，要用系统论的评价方法去评价AI系统，robustnees和稳定性都十分重要，理解robustness有助于更清楚未来的方向。  
* 真正决定一个研究人员的研究成绩的核心因素：对自己领域的激情、投入和勤奋。  
* 认识到自己无知才是好的研究的开始。  
* 计算机能解决很多问题，但是比计算机更厉害的是数学  
* 如何评价优秀的研究：新颖、通用、简单。   
* 做好的研究，在自己的领域中留下名字，首先你要成为历史学家。  
* 好的想法一定来自于大量的积累，多动脑，少计算。  
# 总结  
1.专业架构：statistics+optimization+computing——————machine learning/data science——————AI(CV+NLP)  
2.机器学习分支总结：  
(1)Unsupervised learning: 5 points  
(2)Supervised learning: 5 points, including deap learning:deep neural networks and non-nn style deep models  
(3)Reinforcement learning: MDP,POMAP+alphazero的框架  
3.深度神经网络总结：模型分类：(1)有监督：CNN,RNN(2)无监督：Autoencoder,GAN  
最核心的三个问题：(1)representation(2)optimization(3)generalization  
背后的三朵乌云：(1)robustness(2)generalizaiton(3)interpretability  
4.机器学习以及AI的未来：二维坐标，横坐标表示深度，纵坐标表示agent的数量，将来的智能既有深度又有多个模型，是一个AI系统层面的通用人工智能的框架，其中更深层次的问题是将AI系统去引入因果推断。
